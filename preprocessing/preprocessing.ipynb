{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53624b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e6cc-5119-4a66-84c6-9319a5caff1f",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1af3f9ef-4d0a-4731-adc4-158edc07edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../dataset/raw_dataset.csv\"\n",
    "df_r=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f631e91e-2fe1-44cd-ad0c-e6b73af98c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.drop_duplicates(subset='review').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f9ceb83-2d1b-4d98-a0f3-e6d9fd0aac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "OR    20215\n",
       "CG    20197\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "823a0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'] = df_r['label'].map({'CG': 0, 'OR': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533ac0a-3dab-4022-99c8-2b391a0c56a7",
   "metadata": {},
   "source": [
    "#### Pre Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9da5e",
   "metadata": {},
   "source": [
    "##### Behavioral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d482bf51-d1a1-4977-b4bb-cf385c757289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capital letter ratio\n",
    "def capital_letter_ratio(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if len(letters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    capital_letters = [c for c in letters if c.isupper()]\n",
    "    return len(capital_letters) / len(letters)\n",
    "\n",
    "df_r['capital_ratio'] = df_r['review'].apply(capital_letter_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0776af40-4d8f-4067-9121-a609ae3224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punctuation_ratio\n",
    "def punctuation_ratio(review):\n",
    "    if not isinstance(review, str) or len(review) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    punct_count = len(re.findall(r\"[^\\w\\s]\", review))\n",
    "    return punct_count / len(review)\n",
    "df_r['punctuation_ratio'] = df_r['review'].apply(punctuation_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "039149e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[\"text_length\"] = df_r[\"review\"].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5070bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition score\n",
    "def repetition_score(review):\n",
    "    words = re.findall(r'\\b\\w+\\b', review.lower())\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return 1 - (len(set(words)) / len(words))\n",
    "\n",
    "df_r['repetition_score'] = df_r['review'].apply(repetition_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae722d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare raw reviews\n",
    "reviews = df_r['review'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Step 2: TF-IDF vectorization (raw text)\n",
    "raw_tfidf = TfidfVectorizer(\n",
    "    analyzer='char_wb',  \n",
    "    ngram_range=(3,5),    \n",
    "    max_features=5000,   \n",
    ")\n",
    "\n",
    "X_raw = raw_tfidf.fit_transform(reviews)  \n",
    "\n",
    "# Using cosine distance, sparse matrix compatible\n",
    "raw_nn = NearestNeighbors(\n",
    "    n_neighbors=5, \n",
    "    metric='cosine', \n",
    "    algorithm='brute').fit(X_raw)\n",
    "\n",
    "# Compute nearest neighbors distances for each review\n",
    "distances, indices = raw_nn.kneighbors(X_raw)\n",
    "\n",
    "# Step 4: Convert to similarity score\n",
    "raw_review_similarity_score = 1 - distances\n",
    "\n",
    "# Take **max similarity among neighbors (excluding self)**\n",
    "max_sim = [max(row[1:]) for row in raw_review_similarity_score] \n",
    "\n",
    "# Step 5: Add to dataframe\n",
    "df_r['raw_review_similarity'] = max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6234fe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TF-IDF and NN model saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save models\n",
    "joblib.dump(raw_tfidf, \"../joblib/raw_tfidf_vectorizer.pkl\")\n",
    "joblib.dump(raw_nn, \"../joblib/raw_nn_model.pkl\")\n",
    "\n",
    "print(\"RAW TF-IDF and NN model saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25418f-9107-4778-a126-619248547287",
   "metadata": {},
   "source": [
    "#### Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e5ce1c2-cc36-4a76-9786-42a396525847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraction expansion\n",
    "import contractions\n",
    "def expand_contractions(review):\n",
    "    if pd.isna(review):\n",
    "        return \"\"\n",
    "    return contractions.fix(review)\n",
    "df_r['expanded_text'] = df_r['review'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51ed4258-8477-4c75-99d1-ef862a7fc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text - lowercase, remove url, html tags, punctiation, whitespaces\n",
    "def clean_text(review):\n",
    "    if pd.isna(review):\n",
    "        return \"\"\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    review = re.sub(r'http\\S+|www\\S+', '', review)\n",
    "    review = re.sub(r'<.*?>', '', review)\n",
    "    \n",
    "    # remove punctuation (letters + spaces only)\n",
    "    review = re.sub(r'[^a-z\\s]', '', review)    \n",
    "    review = re.sub(r'\\s+', ' ', review).strip()\n",
    "    \n",
    "    return review\n",
    "\n",
    "df_r['clean_text'] = df_r['expanded_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfa0ca",
   "metadata": {},
   "source": [
    "##### Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1ad43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjective ratio\n",
    "def adjective_ratio(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0\n",
    "    \n",
    "    tokens = word_tokenize(text)        \n",
    "    pos_tags = pos_tag(tokens)          \n",
    "    \n",
    "    adj_count = sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return adj_count / total_words if total_words > 0 else 0\n",
    "df_r['adjective_ratio'] = df_r['clean_text'].apply(adjective_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f203b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment score\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_score(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0.0\n",
    "    return sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "df_r[\"sentiment_score\"] = df_r[\"clean_text\"].apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a65f6",
   "metadata": {},
   "source": [
    "##### Rating Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74d85d0d-d4ff-466d-a2e8-a9b474d7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating polarity\n",
    "def rating_polarity(r):\n",
    "    if r >= 4:\n",
    "        return 1\n",
    "    elif r <= 2:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "df_r[\"rating_polarity\"] = df_r[\"rating\"].apply(rating_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f56810b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating-sentiment mismatch\n",
    "def rating_sentiment_mismatch(row):\n",
    "    sentiment = row['sentiment_score']\n",
    "    rating_pol = row['rating_polarity']\n",
    "\n",
    "    if rating_pol == 1 and sentiment < -0.2:\n",
    "        return 1\n",
    "    if rating_pol == -1 and sentiment > 0.2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_r['rating_sentiment_mismatch'] = df_r.apply(\n",
    "    rating_sentiment_mismatch, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48fbeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme rating\n",
    "df_r['is_extreme_rating'] = df_r['rating'].apply(\n",
    "    lambda x: 1 if x in [1, 5] else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6293e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clean_tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=5000,\n",
    "    min_df=0.05,\n",
    "    max_df=0.9,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_clean = clean_tfidf.fit_transform(df_r['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38b78820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category centroids\n",
    "import numpy as np\n",
    "\n",
    "category_centroids = {}\n",
    "\n",
    "for cat in df_r['category'].unique():\n",
    "    idx = df_r[df_r['category'] == cat].index\n",
    "    category_centroids[cat] = np.asarray(X_clean[idx].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d97fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category consistency using TF-IDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def category_consistency_tfidf(i, category):\n",
    "    if category not in category_centroids:\n",
    "        return 0.0\n",
    "\n",
    "    review_vec = X_clean[i]\n",
    "    centroid_vec = category_centroids[category]\n",
    "\n",
    "    return cosine_similarity(review_vec, centroid_vec)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03587301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category centroids saved\n"
     ]
    }
   ],
   "source": [
    "df_r['category_consistency_score'] = [\n",
    "    category_consistency_tfidf(i, cat)\n",
    "    for i, cat in enumerate(df_r['category'])\n",
    "]\n",
    "\n",
    "joblib.dump(category_centroids, \"../joblib/category_centroids.pkl\")\n",
    "\n",
    "print(\"Category centroids saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea9be8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  lemmatization\n",
    "\n",
    "# nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7f519d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(review):\n",
    "    if pd.isna(review) or review == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp(review)\n",
    "    \n",
    "    lemmatized_words = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_space\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "df_r['lemmatized_text'] = df_r['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5b122b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF on lemmatized text\n",
    "lemm_tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),       \n",
    "    max_features=5000,     \n",
    "    min_df=0.05,\n",
    "    max_df=0.9,\n",
    "    stop_words='english'\n",
    ")\n",
    "X_lemm = lemm_tfidf.fit_transform(df_r['lemmatized_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1b16f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_nn = NearestNeighbors(\n",
    "    n_neighbors=5,\n",
    "    metric=\"cosine\",\n",
    "    algorithm=\"brute\"\n",
    ").fit(X_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6de06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = lemm_nn.kneighbors(X_lemm)\n",
    "\n",
    "# distances are cosine distances â†’ convert to similarity\n",
    "similarities = 1 - distances\n",
    "\n",
    "# ignore self-similarity (index 0)\n",
    "df_r['review_similarity_score'] = similarities[:, 1:].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5043aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized TF-IDF and NN model saved\n"
     ]
    }
   ],
   "source": [
    "# Save models\n",
    "joblib.dump(lemm_tfidf, \"../joblib/lemm_tfidf_vectorizer.pkl\")\n",
    "joblib.dump(lemm_nn, \"../joblib/lemm_nn_model.pkl\")\n",
    "\n",
    "print(\"Lemmatized TF-IDF and NN model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87a3537f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['text_length', 'capital_ratio', 'punctuation_ratio', 'adjective_ratio',\\n       'sentiment_score', 'rating_sentiment_mismatch', 'raw_review_similarity',\\n       'category_consistency_score', 'review_similarity_score',\\n       'repetition_score', 'is_extreme_rating'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hstack\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Select numeric / behavioral features including the new ones\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m numeric_features = \u001b[43mdf_r\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcapital_ratio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpunctuation_ratio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madjective_ratio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrating_sentiment_mismatch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mraw_review_similarity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory_consistency_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreview_similarity_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrepetition_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mis_extreme_rating\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m       \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m]\u001b[49m.values  \u001b[38;5;66;03m# convert to dense numpy array\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Combine TF-IDF vectors with numeric features\u001b[39;00m\n\u001b[32m     20\u001b[39m X_final = hstack([X_tfidf, numeric_features])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\frds\\fake_review_detection\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\frds\\fake_review_detection\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\frds\\fake_review_detection\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['text_length', 'capital_ratio', 'punctuation_ratio', 'adjective_ratio',\\n       'sentiment_score', 'rating_sentiment_mismatch', 'raw_review_similarity',\\n       'category_consistency_score', 'review_similarity_score',\\n       'repetition_score', 'is_extreme_rating'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Feature names (LIST)\n",
    "numeric_feature_names = [\n",
    "    'text_length',\n",
    "    'capital_ratio',\n",
    "    'punctuation_ratio',\n",
    "    'adjective_ratio',\n",
    "    'sentiment_score',\n",
    "    'rating_sentiment_mismatch',\n",
    "    'raw_review_similarity',\n",
    "    'category_consistency_score',\n",
    "    'review_similarity_score',\n",
    "    'repetition_score',        \n",
    "    'is_extreme_rating'\n",
    "]\n",
    "\n",
    "# Feature values (NUMPY ARRAY)\n",
    "numeric_features = (\n",
    "    df_r[numeric_feature_names]\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")\n",
    "    .fillna(0)\n",
    "    .values\n",
    "    .astype(np.float64)\n",
    ")\n",
    "# Combine with TF-IDF\n",
    "X_final = hstack([X_lemm, numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67181291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../joblib/numeric_feature_order.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save feature order for inference\n",
    "joblib.dump(\n",
    "    numeric_feature_names,\n",
    "    \"../joblib/numeric_feature_order.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69d627dd-92f4-49c6-89cf-d785a6961337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'rating', 'label', 'review', 'capital_ratio',\n",
       "       'punctuation_ratio', 'text_length', 'repetition_score',\n",
       "       'raw_review_similarity', 'expanded_text', 'clean_text',\n",
       "       'adjective_ratio', 'sentiment_score', 'rating_polarity',\n",
       "       'rating_sentiment_mismatch', 'is_extreme_rating',\n",
       "       'category_consistency_score', 'review_similarity_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "987fbcd8-887f-4be6-aa6a-3e623395f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final, y_final, numeric features  saved successfully.\n"
     ]
    }
   ],
   "source": [
    "pre_df = df_r[\n",
    "    ['category', 'rating', 'label', 'review', 'capital_ratio',\n",
    "    'punctuation_ratio', 'text_length', 'repetition_score',\n",
    "    'raw_review_similarity', 'expanded_text', 'clean_text',\n",
    "    'adjective_ratio', 'sentiment_score', 'rating_polarity',\n",
    "    'rating_sentiment_mismatch', 'is_extreme_rating',\n",
    "    'category_consistency_score', 'lemmatized_text',\n",
    "    'review_similarity_score']\n",
    "]\n",
    "\n",
    "print(\"X_final, y_final, numeric features  saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc8c3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = df_r['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2617a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final and y_final saved successfully in ../joblib/\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(X_final, \"../joblib/X_final_features.pkl\")\n",
    "joblib.dump(y_final, \"../joblib/y_final_labels.pkl\")\n",
    "\n",
    "print(\"X_final and y_final saved successfully in ../joblib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a6acb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed successfully\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "pre_df.to_csv(\"../dataset/preprocessed_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc8c3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = df_r['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a6acb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final and y_final saved successfully in ../joblib/\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "joblib.dump(X_final, \"../joblib/X_final_features.pkl\")\n",
    "joblib.dump(y_final, \"../joblib/y_final_labels.pkl\")\n",
    "\n",
    "print(\"X_final and y_final saved successfully in ../joblib/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
