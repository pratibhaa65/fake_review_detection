{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53624b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e6cc-5119-4a66-84c6-9319a5caff1f",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3f9ef-4d0a-4731-adc4-158edc07edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"../dataset/raw_dataset.csv\"\n",
    "df_r=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f631e91e-2fe1-44cd-ad0c-e6b73af98c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.drop_duplicates(subset='review').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9ceb83-2d1b-4d98-a0f3-e6d9fd0aac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823a0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'] = df_r['label'].map({'CG': 0, 'OR': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533ac0a-3dab-4022-99c8-2b391a0c56a7",
   "metadata": {},
   "source": [
    "#### Pre Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d482bf51-d1a1-4977-b4bb-cf385c757289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_letter_ratio(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if len(letters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    capital_letters = [c for c in letters if c.isupper()]\n",
    "    return len(capital_letters) / len(letters)\n",
    "df_r['capital_ratio'] = df_r['review'].apply(capital_letter_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0776af40-4d8f-4067-9121-a609ae3224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_ratio(review):\n",
    "    if not isinstance(review, str) or len(review) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    punct_count = len(re.findall(r\"[^\\w\\s]\", review))\n",
    "    return punct_count / len(review)\n",
    "df_r['punctuation_ratio'] = df_r['review'].apply(punctuation_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039149e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['text_length'] = df_r['review'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition score\n",
    "def repetition_score(review):\n",
    "    words = re.findall(r'\\b\\w+\\b', review.lower())\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return 1 - (len(set(words)) / len(words))\n",
    "\n",
    "df_r['repetition_score'] = df_r['review'].apply(repetition_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae722d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare raw reviews\n",
    "reviews = df_r['review'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Step 2: TF-IDF vectorization (raw text)\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='char_wb',  \n",
    "    ngram_range=(3,5),    \n",
    "    max_features=10000,   \n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(reviews)  \n",
    "\n",
    "# Using cosine distance, sparse matrix compatible\n",
    "nbrs = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute').fit(X)\n",
    "\n",
    "# Compute nearest neighbors distances for each review\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "# Step 4: Convert to similarity score\n",
    "raw_review_similarity_score = 1 - distances\n",
    "\n",
    "# Take **max similarity among neighbors (excluding self)**\n",
    "max_sim = [max(row[1:]) for row in raw_review_similarity_score] \n",
    "\n",
    "# Step 5: Add to dataframe\n",
    "df_r['raw_review_similarity'] = max_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25418f-9107-4778-a126-619248547287",
   "metadata": {},
   "source": [
    "#### Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5ce1c2-cc36-4a76-9786-42a396525847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraction expansion\n",
    "import contractions\n",
    "def expand_contractions(review):\n",
    "    if pd.isna(review):\n",
    "        return \"\"\n",
    "    return contractions.fix(review)\n",
    "df_r['expanded_text'] = df_r['review'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed4258-8477-4c75-99d1-ef862a7fc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text - lowercase, remove url, html tags, punctiation, whitespaces\n",
    "def clean_text(review):\n",
    "    if pd.isna(review):\n",
    "        return \"\"\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    review = re.sub(r'http\\S+|www\\S+', '', review)\n",
    "    review = re.sub(r'<.*?>', '', review)\n",
    "    \n",
    "    # remove punctuation (letters + spaces only)\n",
    "    review = re.sub(r'[^a-z\\s]', '', review)    \n",
    "    review = re.sub(r'\\s+', ' ', review).strip()\n",
    "    \n",
    "    return review\n",
    "df_r['clean_text'] = df_r['expanded_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4d540-45a7-4093-9d8a-a8c0f528d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjective ratio\n",
    "def adjective_ratio(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0\n",
    "    \n",
    "    tokens = word_tokenize(text)        \n",
    "    pos_tags = pos_tag(tokens)          \n",
    "    \n",
    "    adj_count = sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return adj_count / total_words if total_words > 0 else 0\n",
    "df_r['adjective_ratio'] = df_r['clean_text'].apply(adjective_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d85d0d-d4ff-466d-a2e8-a9b474d7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment score\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def sentiment_score(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Compound score ranges from -1 (very negative) to +1 (very positive)\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "df_r['sentiment_score'] = df_r['clean_text'].apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f203b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating polarity\n",
    "def rating_polarity(r):\n",
    "    if r >= 4:\n",
    "        return 1\n",
    "    elif r <= 2:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_r['rating_polarity'] = df_r['rating'].apply(rating_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating-sentiment mismatch\n",
    "def rating_sentiment_mismatch(row):\n",
    "    sentiment = row['sentiment_score']\n",
    "    rating_pol = row['rating_polarity']\n",
    "\n",
    "    if rating_pol == 1 and sentiment < -0.2:\n",
    "        return 1\n",
    "    if rating_pol == -1 and sentiment > 0.2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_r['rating_sentiment_mismatch'] = df_r.apply(\n",
    "    rating_sentiment_mismatch, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9365ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme rating\n",
    "df_r['is_extreme_rating'] = df_r['rating'].apply(\n",
    "    lambda x: 1 if x in [1, 5] else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(df_r['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b78820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category centroids\n",
    "import numpy as np\n",
    "\n",
    "category_centroids = {}\n",
    "\n",
    "for cat in df_r['category'].unique():\n",
    "    idx = df_r[df_r['category'] == cat].index\n",
    "    category_centroids[cat] = np.asarray(X[idx].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03587301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category consistency using TF-IDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def category_consistency_tfidf(i, category):\n",
    "    if category not in category_centroids:\n",
    "        return 0.0\n",
    "\n",
    "    review_vec = X[i]\n",
    "    centroid_vec = category_centroids[category]\n",
    "\n",
    "    return cosine_similarity(review_vec, centroid_vec)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46dafe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['category_consistency_score'] = [\n",
    "    category_consistency_tfidf(i, cat)\n",
    "    for i, cat in enumerate(df_r['category'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea9be8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lemmatization\n",
    "\n",
    "# nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7f519d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(review):\n",
    "    if pd.isna(review) or review == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp(review)\n",
    "    \n",
    "    lemmatized_words = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_space\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)\n",
    "df_r['lemmatized_text'] = df_r['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b122b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF on lemmatized text\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),       \n",
    "    max_features=5000,     \n",
    "    min_df=0.05,\n",
    "    max_df=0.9,\n",
    "    stop_words='english'\n",
    ")\n",
    "X_tfidf = tfidf.fit_transform(df_r['lemmatized_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1b16f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(\n",
    "    n_neighbors=5,      \n",
    "    metric='cosine',\n",
    "    algorithm='brute'\n",
    ")\n",
    "\n",
    "nn.fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6de06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nn.kneighbors(X_tfidf)\n",
    "\n",
    "# distances are cosine distances â†’ convert to similarity\n",
    "similarities = 1 - distances\n",
    "\n",
    "# ignore self-similarity (index 0)\n",
    "df_r['review_similarity_score'] = similarities[:, 1:].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87a3537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "# Select numeric / behavioral features including the new ones\n",
    "numeric_features = df_r[\n",
    "    [\n",
    "        'text_length',\n",
    "        'capital_ratio',\n",
    "        'punctuation_ratio',\n",
    "        'adjective_ratio',\n",
    "        'sentiment_score',\n",
    "        'rating_sentiment_mismatch',\n",
    "        'raw_review_similarity',\n",
    "        'category_consistency_score',\n",
    "        'review_similarity_score',\n",
    "        'repetition_score',        \n",
    "        'is_extreme_rating'       \n",
    "    ]\n",
    "].values  # convert to dense numpy array\n",
    "\n",
    "# Combine TF-IDF vectors with numeric features\n",
    "X_final = hstack([X_tfidf, numeric_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69d627dd-92f4-49c6-89cf-d785a6961337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "987fbcd8-887f-4be6-aa6a-3e623395f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = df_r[\n",
    "    ['category', 'rating', 'label', 'review', 'capital_ratio',\n",
    "    'punctuation_ratio', 'text_length', 'repetition_score',\n",
    "    'raw_review_similarity', 'expanded_text', 'clean_text',\n",
    "    'adjective_ratio', 'sentiment_score', 'rating_polarity',\n",
    "    'rating_sentiment_mismatch', 'is_extreme_rating',\n",
    "    'category_consistency_score', 'lemmatized_text',\n",
    "    'review_similarity_score']\n",
    "]\n",
    "\n",
    "# Save as CSV\n",
    "pre_df.to_csv(\"../dataset/preprocessed_dataset.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved as CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = df_r['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6acb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "joblib.dump(X_final, \"../joblib/X_final_features.pkl\")\n",
    "joblib.dump(y_final, \"../joblib/y_final_labels.pkl\")\n",
    "\n",
    "print(\"X_final and y_final saved successfully in ../joblib/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
