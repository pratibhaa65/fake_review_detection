{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbdcb66e-6c3e-4bea-9080-35be22511c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: regex in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (2025.11.3)\n",
      "Requirement already satisfied: contractions in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: click in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (0.21.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
      "Requirement already satisfied: anyascii in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: wrapt in c:\\users\\prati\\fake_review_detection\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas nltk spacy regex contractions scikit-learn \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53624b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e6cc-5119-4a66-84c6-9319a5caff1f",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af3f9ef-4d0a-4731-adc4-158edc07edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"raw_dataset.csv\"\n",
    "print(\"File exists:\", os.path.exists(file_path))\n",
    "df_r=pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb6297d7-e1f7-4aed-a224-8fe243d3ec43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f3bc46-b5b2-44a6-929f-cea899b0fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40432 entries, 0 to 40431\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   category  40432 non-null  object \n",
      " 1   rating    40432 non-null  float64\n",
      " 2   label     40432 non-null  object \n",
      " 3   text_     40432 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_r.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59b89ac6-0272-41d1-8468-f4fa428dbcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0\n",
       "rating      0\n",
       "label       0\n",
       "text_       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83357843-96b8-4f20-86da-9e1b12582639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['text_'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f631e91e-2fe1-44cd-ad0c-e6b73af98c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.drop_duplicates(subset='text_').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37773f96-cb07-4767-a99e-4a19577c1be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['text_'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f9ceb83-2d1b-4d98-a0f3-e6d9fd0aac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "OR    20215\n",
       "CG    20197\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23db4368-27b1-4182-ab31-08838d967989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'rating', 'label', 'text_'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533ac0a-3dab-4022-99c8-2b391a0c56a7",
   "metadata": {},
   "source": [
    "#### Pre Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d482bf51-d1a1-4977-b4bb-cf385c757289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_letter_ratio(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if len(letters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    capital_letters = [c for c in letters if c.isupper()]\n",
    "    return len(capital_letters) / len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71088730-59bc-409a-9a03-939208d5f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "      <th>capital_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>0.070175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They are the perfect touch for me and the only...</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These done fit well and look great.  I love th...</td>\n",
       "      <td>0.029851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Great big numbers &amp; easy to read, the only thi...</td>\n",
       "      <td>0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My son loves this comforter and it is very wel...</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_  capital_ratio\n",
       "0  Love this!  Well made, sturdy, and very comfor...       0.070175\n",
       "1  love it, a great upgrade from the original.  I...       0.016393\n",
       "2  This pillow saved my back. I love the look and...       0.038462\n",
       "3  Missing information on how to use it, but it i...       0.032258\n",
       "4  Very nice set. Good quality. We have had the s...       0.045455\n",
       "5       I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.       1.000000\n",
       "6  They are the perfect touch for me and the only...       0.028571\n",
       "7  These done fit well and look great.  I love th...       0.029851\n",
       "8  Great big numbers & easy to read, the only thi...       0.032787\n",
       "9  My son loves this comforter and it is very wel...       0.035088"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['capital_ratio'] = df_r['text_'].apply(capital_letter_ratio)\n",
    "df_r[['text_', 'capital_ratio']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776af40-4d8f-4067-9121-a609ae3224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_ratio(text_):\n",
    "    if not isinstance(text_, str) or len(text_) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    punct_count = len(re.findall(r\"[^\\w\\s]\", text_))\n",
    "    return punct_count / len(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "213582a6-6b2e-4275-aa46-072ce9d21b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>0.029851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>0.024691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>0.023529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They are the perfect touch for me and the only...</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These done fit well and look great.  I love th...</td>\n",
       "      <td>0.011765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Great big numbers &amp; easy to read, the only thi...</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My son loves this comforter and it is very wel...</td>\n",
       "      <td>0.013514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_  punctuation_ratio\n",
       "0  Love this!  Well made, sturdy, and very comfor...           0.066667\n",
       "1  love it, a great upgrade from the original.  I...           0.037500\n",
       "2  This pillow saved my back. I love the look and...           0.029851\n",
       "3  Missing information on how to use it, but it i...           0.024691\n",
       "4  Very nice set. Good quality. We have had the s...           0.023529\n",
       "5       I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.           0.022727\n",
       "6  They are the perfect touch for me and the only...           0.011236\n",
       "7  These done fit well and look great.  I love th...           0.011765\n",
       "8  Great big numbers & easy to read, the only thi...           0.037037\n",
       "9  My son loves this comforter and it is very wel...           0.013514"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['punctuation_ratio'] = df_r['text_'].apply(punctuation_ratio)\n",
    "df_r[['text_', 'punctuation_ratio']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd1b0d4a-ecdb-47fb-9f82-da738f51f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excessive_punctuation_ratio(text):\n",
    "    if not isinstance(text, str) or len(text) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    matches = re.findall(r\"[!?]{2,}\", text)\n",
    "    excessive_count = sum(len(m) for m in matches)\n",
    "\n",
    "    return excessive_count / len(text)\n",
    "\n",
    "\n",
    "def excessive_punctuation_flag(text, threshold=0.05):\n",
    "    if(excessive_punctuation_ratio(text) > threshold):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b8fa010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['excessive_punctuation_ratio'] = df_r['text_'].apply(\n",
    "    excessive_punctuation_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1ac29-591c-40da-9410-6c781cb63e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8605f70d-0aaf-4b06-8474-0bbd55357e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "      <th>capital_ratio</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>excessive_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They are the perfect touch for me and the only...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These done fit well and look great.  I love th...</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Great big numbers &amp; easy to read, the only thi...</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My son loves this comforter and it is very wel...</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_  capital_ratio  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...       0.070175   \n",
       "1  love it, a great upgrade from the original.  I...       0.016393   \n",
       "2  This pillow saved my back. I love the look and...       0.038462   \n",
       "3  Missing information on how to use it, but it i...       0.032258   \n",
       "4  Very nice set. Good quality. We have had the s...       0.045455   \n",
       "5       I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.       1.000000   \n",
       "6  They are the perfect touch for me and the only...       0.028571   \n",
       "7  These done fit well and look great.  I love th...       0.029851   \n",
       "8  Great big numbers & easy to read, the only thi...       0.032787   \n",
       "9  My son loves this comforter and it is very wel...       0.035088   \n",
       "\n",
       "   punctuation_count  excessive_punctuation  \n",
       "0                  5                      0  \n",
       "1                  3                      0  \n",
       "2                  2                      0  \n",
       "3                  2                      0  \n",
       "4                  2                      0  \n",
       "5                  1                      0  \n",
       "6                  1                      0  \n",
       "7                  1                      0  \n",
       "8                  3                      0  \n",
       "9                  1                      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r[['text_', 'capital_ratio', 'punctuation_count', 'excessive_punctuation']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25418f-9107-4778-a126-619248547287",
   "metadata": {},
   "source": [
    "#### Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e5ce1c2-cc36-4a76-9786-42a396525847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraction expansion\n",
    "import contractions\n",
    "def expand_contractions(text_):\n",
    "    if pd.isna(text_):\n",
    "        return \"\"\n",
    "    return contractions.fix(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb2de3ef-e8e7-4d46-af5a-ac2d1410f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: I don't like this product\n",
      "AFTER : I do not like this product\n",
      "----------------------------------------\n",
      "BEFORE: It's not what I've expected\n",
      "AFTER : It is not what I have expected\n",
      "----------------------------------------\n",
      "BEFORE: You're going to love it\n",
      "AFTER : You are going to love it\n",
      "----------------------------------------\n",
      "BEFORE: They can't believe it's true\n",
      "AFTER : They cannot believe it is true\n",
      "----------------------------------------\n",
      "BEFORE: This is fine\n",
      "AFTER : This is fine\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"I don't like this product\",\n",
    "    \"It's not what I've expected\",\n",
    "    \"You're going to love it\",\n",
    "    \"They can't believe it's true\",\n",
    "    \"This is fine\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(\"BEFORE:\", s)\n",
    "    print(\"AFTER :\", expand_contractions(s))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51ed4258-8477-4c75-99d1-ef862a7fc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text - lowercase, url, html tags, punctiation, whitespaces\n",
    "def clean_text(text_):\n",
    "    if pd.isna(text_):\n",
    "        return \"\"\n",
    "    \n",
    "    text_ = text_.lower()\n",
    "    \n",
    "    text_ = re.sub(r'http\\S+|www\\S+', '', text_)\n",
    "    text_ = re.sub(r'<.*?>', '', text_)\n",
    "    \n",
    "    # remove punctuation (letters + spaces only)\n",
    "    text_ = re.sub(r'[^a-z\\s]', '', text_)\n",
    "    \n",
    "    text_ = re.sub(r'\\s+', ' ', text_).strip()\n",
    "    \n",
    "    return text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2f299b0-7bdc-4471-8077-99250cb533e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['expanded_text'] = df_r['text_'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a453bfb1-19b8-482e-b470-679639c508d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['clean_text'] = df_r['expanded_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c39c574-3ffc-41c1-9592-db150738cc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "      <th>expanded_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40101</th>\n",
       "      <td>Since we can never have enough umbrellas, I wa...</td>\n",
       "      <td>Since we can never have enough umbrellas, I wa...</td>\n",
       "      <td>since we can never have enough umbrellas i was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>ThinkFun provided me with this new Daily Puzzl...</td>\n",
       "      <td>ThinkFun provided me with this new Daily Puzzl...</td>\n",
       "      <td>thinkfun provided me with this new daily puzzl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38275</th>\n",
       "      <td>WAY too large, I have a 9 1/2\" wrist and it fi...</td>\n",
       "      <td>WAY too large, I have a 9 1/2\" wrist and it fi...</td>\n",
       "      <td>way too large i have a wrist and it fits just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27254</th>\n",
       "      <td>This was an Awesome read.  The characters were...</td>\n",
       "      <td>This was an Awesome read.  The characters were...</td>\n",
       "      <td>this was an awesome read the characters were w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>Bought this to try for reducing wind noise whi...</td>\n",
       "      <td>Bought this to try for reducing wind noise whi...</td>\n",
       "      <td>bought this to try for reducing wind noise whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text_  \\\n",
       "40101  Since we can never have enough umbrellas, I wa...   \n",
       "35870  ThinkFun provided me with this new Daily Puzzl...   \n",
       "38275  WAY too large, I have a 9 1/2\" wrist and it fi...   \n",
       "27254  This was an Awesome read.  The characters were...   \n",
       "7427   Bought this to try for reducing wind noise whi...   \n",
       "\n",
       "                                           expanded_text  \\\n",
       "40101  Since we can never have enough umbrellas, I wa...   \n",
       "35870  ThinkFun provided me with this new Daily Puzzl...   \n",
       "38275  WAY too large, I have a 9 1/2\" wrist and it fi...   \n",
       "27254  This was an Awesome read.  The characters were...   \n",
       "7427   Bought this to try for reducing wind noise whi...   \n",
       "\n",
       "                                              clean_text  \n",
       "40101  since we can never have enough umbrellas i was...  \n",
       "35870  thinkfun provided me with this new daily puzzl...  \n",
       "38275  way too large i have a wrist and it fits just ...  \n",
       "27254  this was an awesome read the characters were w...  \n",
       "7427   bought this to try for reducing wind noise whi...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r[['text_', 'expanded_text', 'clean_text']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28f0724d-6c18-42cc-8c3e-86efa3a5abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : WOW!!! 10/10 would buy again!!! üòç\n",
      "OUTPUT: wow would buy again\n",
      "------------------------------\n",
      "INPUT : <p>Best product ever</p>\n",
      "OUTPUT: best product ever\n",
      "------------------------------\n",
      "INPUT : Visit http://example.com NOW\n",
      "OUTPUT: visit now\n",
      "------------------------------\n",
      "INPUT :    Multiple     spaces   \n",
      "OUTPUT: multiple spaces\n",
      "------------------------------\n",
      "INPUT : None\n",
      "OUTPUT: \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    \"WOW!!! 10/10 would buy again!!! üòç\",\n",
    "    \"<p>Best product ever</p>\",\n",
    "    \"Visit http://example.com NOW\",\n",
    "    \"   Multiple     spaces   \",\n",
    "    None\n",
    "]\n",
    "\n",
    "for t in test_cases:\n",
    "    print(\"INPUT :\", t)\n",
    "    print(\"OUTPUT:\", clean_text(t))\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d89fd1f-3d72-4db8-acbc-9969b8f40862",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# lemmatization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# nltk resources\u001b[39;00m\n\u001b[32m      5\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mpunkt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\nltk\\__init__.py:134\u001b[39m\n\u001b[32m    126\u001b[39m     subprocess.Popen = _fake_Popen\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# TOP-LEVEL MODULES\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[32m    131\u001b[39m \n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Import top-level functionality into top-level namespace\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollocations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator, memoize\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatstruct\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\nltk\\collocations.py:36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_itertools\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# these two unused imports are referenced in collocations.doctest\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     BigramAssocMeasures,\n\u001b[32m     38\u001b[39m     ContingencyMeasures,\n\u001b[32m     39\u001b[39m     QuadgramAssocMeasures,\n\u001b[32m     40\u001b[39m     TrigramAssocMeasures,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspearman\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ranks_from_scores, spearman_correlation\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprobability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\nltk\\metrics\\__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magreement\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnnotationTask\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m align\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01massociation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     BigramAssocMeasures,\n\u001b[32m     20\u001b[39m     ContingencyMeasures,\n\u001b[32m     21\u001b[39m     NgramAssocMeasures,\n\u001b[32m     22\u001b[39m     QuadgramAssocMeasures,\n\u001b[32m     23\u001b[39m     TrigramAssocMeasures,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfusionmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrix\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     binary_distance,\n\u001b[32m     28\u001b[39m     custom_distance,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     presence,\n\u001b[32m     36\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\nltk\\metrics\\association.py:26\u001b[39m\n\u001b[32m     23\u001b[39m _SMALL = \u001b[32m1e-20\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fisher_exact\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfisher_exact\u001b[39m(*_args, **_kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\stats\\__init__.py:628\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m \n\u001b[32m    624\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_warnings_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[32m    627\u001b[39m                                DegenerateDataWarning, FitError)\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m milp, LinearConstraint\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1231\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\__init__.py:143\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name):\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\sparse\\__init__.py:307\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_warnings\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_importlib\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\sparse\\_base.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[32m      9\u001b[39m                        get_sum_dtype, isdense, isscalarlike, _todata,\n\u001b[32m     10\u001b[39m                        matrix, validateaxis, getdtype, is_pydata_spmatrix)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseABC, issparse\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\sparse\\_sputils.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prod\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m np_long, np_ulong\n\u001b[32m     13\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mupcast\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgetdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgetdata\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33misscalarlike\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33misintlike\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m            \u001b[33m'\u001b[39m\u001b[33misshape\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33missequence\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33misdense\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mismatrix\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mget_sum_dtype\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mbroadcast_shapes\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     17\u001b[39m supported_dtypes = [np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc,\n\u001b[32m     18\u001b[39m                     np.uintc, np_long, np_ulong, np.longlong, np.ulonglong,\n\u001b[32m     19\u001b[39m                     np.float32, np.float64, np.longdouble,\n\u001b[32m     20\u001b[39m                     np.complex64, np.complex128, np.clongdouble]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal, TypeAlias, TypeVar\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Array, array_namespace, is_lazy_array, is_numpy,\n\u001b[32m     18\u001b[39m                                    is_marray, xp_size, xp_result_device, xp_result_type)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docscrape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionDoc, Parameter\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\_lib\\_array_api.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnpt\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     is_array_api_obj,\n\u001b[32m     26\u001b[39m     is_lazy_array,\n\u001b[32m     27\u001b[39m     is_numpy_array,\n\u001b[32m     28\u001b[39m     is_cupy_array,\n\u001b[32m     29\u001b[39m     is_torch_array,\n\u001b[32m     30\u001b[39m     is_jax_array,\n\u001b[32m     31\u001b[39m     is_dask_array,\n\u001b[32m     32\u001b[39m     size \u001b[38;5;28;01mas\u001b[39;00m xp_size,\n\u001b[32m     33\u001b[39m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[32m     34\u001b[39m     device \u001b[38;5;28;01mas\u001b[39;00m xp_device,\n\u001b[32m     35\u001b[39m     is_numpy_namespace \u001b[38;5;28;01mas\u001b[39;00m is_numpy,\n\u001b[32m     36\u001b[39m     is_cupy_namespace \u001b[38;5;28;01mas\u001b[39;00m is_cupy,\n\u001b[32m     37\u001b[39m     is_torch_namespace \u001b[38;5;28;01mas\u001b[39;00m is_torch,\n\u001b[32m     38\u001b[39m     is_jax_namespace \u001b[38;5;28;01mas\u001b[39;00m is_jax,\n\u001b[32m     39\u001b[39m     is_dask_namespace \u001b[38;5;28;01mas\u001b[39;00m is_dask,\n\u001b[32m     40\u001b[39m     is_array_api_strict_namespace \u001b[38;5;28;01mas\u001b[39;00m is_array_api_strict,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _compat_module_name\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_extra\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lazy_xp_function\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\_lib\\array_api_compat\\numpy\\__init__.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# This needs to be loaded explicitly before cloning\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtyping\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m __all__ = \u001b[43mclone_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnumpy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# These imports may overwrite names from the import * above.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _aliases\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\scipy\\_lib\\array_api_compat\\_internal.py:64\u001b[39m, in \u001b[36mclone_module\u001b[39m\u001b[34m(mod_name, globals_)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Neither of these two methods is sufficient by itself,\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# depending on various idiosyncrasies of the libraries we're wrapping.\u001b[39;00m\n\u001b[32m     63\u001b[39m objs = {}\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrom \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m import *\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(mod):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(mod, n):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1229\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1231\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\numpy\\__init__.py:725\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m linalg\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33mfft\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfft\u001b[39;00m\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fft\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33mdtypes\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\numpy\\fft\\__init__.py:203\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mDiscrete Fourier Transform\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m==========================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \n\u001b[32m    201\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _helper, _pocketfft\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_helper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pocketfft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prati\\fake_review_detection\\venv\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:48\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     asarray,\n\u001b[32m     38\u001b[39m     conjugate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     take,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize_axis_index\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pocketfft_umath \u001b[38;5;28;01mas\u001b[39;00m pfu\n\u001b[32m     50\u001b[39m array_function_dispatch = functools.partial(\n\u001b[32m     51\u001b[39m     overrides.array_function_dispatch, module=\u001b[33m'\u001b[39m\u001b[33mnumpy.fft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# `inv_norm` is a float by which the result of the transform needs to be\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# divided. This replaces the original, more intuitive 'fct` parameter to avoid\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# divisions by zero (or alternatively additional checks) in the case of\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# zero-length axes during its computation.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "import nltk\n",
    "\n",
    "# nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04968bf-7d36-46e0-8563-e449c5aff47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742214b-b1e8-4db8-b93d-2b687a4a47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lemmatization tools\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4d540-45a7-4093-9d8a-a8c0f528d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjective_ratio(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0\n",
    "    \n",
    "    tokens = word_tokenize(text)        \n",
    "    pos_tags = pos_tag(tokens)          \n",
    "    \n",
    "    adj_count = sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return adj_count / total_words if total_words > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b88f3-deb0-458f-a77c-3ecc2c3b75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['adjective_ratio'] = df_r['clean_text'].apply(adjective_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c15b47-0742-4489-8aa2-2b821222d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['clean_text', 'adjective_ratio']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d85d0d-d4ff-466d-a2e8-a9b474d7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e8077-1d2d-419e-9ca5-a8babc5166e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Compound score ranges from -1 (very negative) to +1 (very positive)\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18dd2a-8ebc-40d1-9d59-13d9a802e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['sentiment_score'] = df_r['clean_text'].apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52019ce4-4adc-4843-a62d-7c27ad99c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['clean_text', 'sentiment_score']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9062de-f137-402c-b839-b2dd74530bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['text_length'] = df_r['clean_text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b014f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9662939-413c-40de-8e41-475d181f17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lemmatize_text(text_):\n",
    "    if pd.isna(text_) or text_ == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp(text_)\n",
    "    \n",
    "    lemmatized_words = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_space\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "544deb47-e042-437b-b731-cc9a4ec8520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: running faster than others\n",
      "AFTER : run fast than other\n",
      "----------------------------------------\n",
      "BEFORE: better products were bought\n",
      "AFTER : well product be buy\n",
      "----------------------------------------\n",
      "BEFORE: he was buying expensive items\n",
      "AFTER : he be buy expensive item\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"running faster than others\",\n",
    "    \"better products were bought\",\n",
    "    \"he was buying expensive items\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(\"BEFORE:\", s)\n",
    "    print(\"AFTER :\", lemmatize_text(s))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f02f5d-6b51-4292-a17d-12019b91cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['lemmatized_text'] = df_r['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef644cd-85e8-4353-bf6d-a43808a31522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['text_', 'expanded_text', 'clean_text', 'lemmatized_text']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921c3f5-8265-46ee-86a7-98514dfafeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.rename(columns={'lemmatized_text': 'review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e39e5d-6e80-4651-89e4-0739ccbbd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'] = df_r['label'].map({'CG': 0, 'OR': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cbf2f-4489-458e-b891-1b7a4c5619a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=0.05,\n",
    "    max_df=0.9,\n",
    "    stop_words=None\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(df_r['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe217ee-aa2f-46f3-b3dd-26af08395cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a646f7c-e333-4886-ab01-9e372472ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37028a51-ddc9-4986-bd69-b798a59503b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf                   \n",
    "df_r[['adjective_ratio',\n",
    "      'sentiment_score',\n",
    "      'text_length',\n",
    "      'capital_ratio',\n",
    "      'punctuation_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1520d-7f08-49a7-b3f2-d404ee932314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_extra = df_r[\n",
    "    ['adjective_ratio',\n",
    "     'sentiment_score',\n",
    "     'text_length',\n",
    "     'capital_ratio',\n",
    "     'punctuation_count']\n",
    "].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c5c9c-4a18-4f71-9e08-04aeecc22772",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b89939-bd24-4d08-9394-8ec55f3fd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = hstack([X_tfidf, X_extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e91225-6a96-44e9-a1d4-5c1c27e21b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf.shape\n",
    "X_extra.shape\n",
    "X_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa2b39-d4d4-46e1-bc39-4f8444a60788",
   "metadata": {},
   "source": [
    "#### Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d627dd-92f4-49c6-89cf-d785a6961337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fbcd8-887f-4be6-aa6a-3e623395f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = df_r[\n",
    "    ['text_','clean_text', 'review', 'rating','label', 'text_length',\n",
    "     'capital_ratio', 'punctuation_count', 'excessive_punctuation',\n",
    "     'adjective_ratio', 'sentiment_score']\n",
    "]\n",
    "\n",
    "# Save as CSV\n",
    "pre_df.to_csv(\"preprocessed_dataset.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved as CSV!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
