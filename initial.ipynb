{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbdcb66e-6c3e-4bea-9080-35be22511c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in .\\venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in .\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: nltk in .\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in .\\venv\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: regex in .\\venv\\lib\\site-packages (2025.11.3)\n",
      "Requirement already satisfied: contractions in .\\venv\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: scikit-learn in .\\venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: click in .\\venv\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in .\\venv\\lib\\site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: tqdm in .\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in .\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in .\\venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in .\\venv\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in .\\venv\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in .\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in .\\venv\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in .\\venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in .\\venv\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in .\\venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in .\\venv\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in .\\venv\\lib\\site-packages (from spacy) (0.21.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in .\\venv\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in .\\venv\\lib\\site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in .\\venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in .\\venv\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in .\\venv\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: scipy>=1.10.0 in .\\venv\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in .\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in .\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in .\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
      "Requirement already satisfied: anyascii in .\\venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in .\\venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in .\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in .\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in .\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in .\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\venv\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: wrapt in .\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas nltk spacy regex contractions scikit-learn \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53624b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e6cc-5119-4a66-84c6-9319a5caff1f",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1af3f9ef-4d0a-4731-adc4-158edc07edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"raw_dataset.csv\"\n",
    "df_r=pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f631e91e-2fe1-44cd-ad0c-e6b73af98c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.drop_duplicates(subset='review').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f9ceb83-2d1b-4d98-a0f3-e6d9fd0aac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "OR    20215\n",
       "CG    20197\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "823a0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'] = df_r['label'].map({'CG': 0, 'OR': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533ac0a-3dab-4022-99c8-2b391a0c56a7",
   "metadata": {},
   "source": [
    "#### Pre Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482bf51-d1a1-4977-b4bb-cf385c757289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_letter_ratio(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if len(letters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    capital_letters = [c for c in letters if c.isupper()]\n",
    "    return len(capital_letters) / len(letters)\n",
    "df_r['capital_ratio'] = df_r['review'].apply(capital_letter_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776af40-4d8f-4067-9121-a609ae3224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_ratio(review):\n",
    "    if not isinstance(review, str) or len(review) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    punct_count = len(re.findall(r\"[^\\w\\s]\", review))\n",
    "    return punct_count / len(review)\n",
    "df_r['punctuation_ratio'] = df_r['review'].apply(punctuation_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039149e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['text_length'] = df_r['review'].apply(lambda x: len(str(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25418f-9107-4778-a126-619248547287",
   "metadata": {},
   "source": [
    "#### Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ce1c2-cc36-4a76-9786-42a396525847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraction expansion\n",
    "import contractions\n",
    "def expand_contractions(review):\n",
    "    if pd.isna(review):\n",
    "        return \"\"\n",
    "    return contractions.fix(review)\n",
    "df_r['expanded_text'] = df_r['review'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed4258-8477-4c75-99d1-ef862a7fc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text - lowercase, remove url, html tags, punctiation, whitespaces\n",
    "def clean_text(review):\n",
    "    if pd.isna(review):\n",
    "        return \"\"\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    review = re.sub(r'http\\S+|www\\S+', '', review)\n",
    "    review = re.sub(r'<.*?>', '', review)\n",
    "    \n",
    "    # remove punctuation (letters + spaces only)\n",
    "    review = re.sub(r'[^a-z\\s]', '', review)\n",
    "    \n",
    "    review = re.sub(r'\\s+', ' ', review).strip()\n",
    "    \n",
    "    return review\n",
    "df_r['clean_text'] = df_r['expanded_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89fd1f-3d72-4db8-acbc-9969b8f40862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "# nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4d540-45a7-4093-9d8a-a8c0f528d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjective_ratio(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0\n",
    "    \n",
    "    tokens = word_tokenize(text)        \n",
    "    pos_tags = pos_tag(tokens)          \n",
    "    \n",
    "    adj_count = sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return adj_count / total_words if total_words > 0 else 0\n",
    "df_r['adjective_ratio'] = df_r['clean_text'].apply(adjective_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d85d0d-d4ff-466d-a2e8-a9b474d7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def sentiment_score(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Compound score ranges from -1 (very negative) to +1 (very positive)\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "df_r['sentiment_score'] = df_r['clean_text'].apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "\n",
    "def lemmatize_text(review):\n",
    "    if pd.isna(review) or review == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp(review)\n",
    "    \n",
    "    lemmatized_words = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_space\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)\n",
    "df_r['review'] = df_r['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa2b39-d4d4-46e1-bc39-4f8444a60788",
   "metadata": {},
   "source": [
    "#### Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69d627dd-92f4-49c6-89cf-d785a6961337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'rating', 'label', 'text_', 'capital_ratio',\n",
       "       'punctuation_ratio', 'is_excessive_punctuation', 'expanded_text',\n",
       "       'clean_text', 'adjective_ratio', 'sentiment_score', 'text_length',\n",
       "       'review'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fbcd8-887f-4be6-aa6a-3e623395f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = df_r[\n",
    "    ['review','clean_text', 'review', 'rating','label', 'reviewlength',\n",
    "     'capital_ratio', 'punctuation_ratio', 'is_excessive_punctuation',\n",
    "     'adjective_ratio', 'sentiment_score']\n",
    "]\n",
    "\n",
    "# Save as CSV\n",
    "pre_df.to_csv(\"preprocessed_dataset.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved as CSV!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
