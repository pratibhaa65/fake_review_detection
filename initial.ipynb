{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdcb66e-6c3e-4bea-9080-35be22511c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas nltk spacy regex contractions scikit-learn \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53624b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e6cc-5119-4a66-84c6-9319a5caff1f",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3f9ef-4d0a-4731-adc4-158edc07edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"raw_dataset.csv\"\n",
    "print(\"File exists:\", os.path.exists(file_path))\n",
    "df_r=pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6297d7-e1f7-4aed-a224-8fe243d3ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3bc46-b5b2-44a6-929f-cea899b0fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b89ac6-0272-41d1-8468-f4fa428dbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83357843-96b8-4f20-86da-9e1b12582639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['text_'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631e91e-2fe1-44cd-ad0c-e6b73af98c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.drop_duplicates(subset='text_').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37773f96-cb07-4767-a99e-4a19577c1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['text_'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ceb83-2d1b-4d98-a0f3-e6d9fd0aac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31708ac7-8aca-4569-8027-6f0d6fdf61d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db4368-27b1-4182-ab31-08838d967989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533ac0a-3dab-4022-99c8-2b391a0c56a7",
   "metadata": {},
   "source": [
    "#### Pre Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482bf51-d1a1-4977-b4bb-cf385c757289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_letter_ratio(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if len(letters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    capital_letters = [c for c in letters if c.isupper()]\n",
    "    return len(capital_letters) / len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138596e-8f9c-402a-aae3-54648ab8e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"This product is amazing\",\n",
    "    \"THIS PRODUCT IS AMAZING\",\n",
    "    \"Amazing Product!!! MUST BUY\",\n",
    "    \"bAd\",\n",
    "    \"\",\n",
    "    \"OKAY\"\n",
    "]\n",
    "for text in test_texts:\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Capital Ratio:\", capital_letter_ratio(text))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71088730-59bc-409a-9a03-939208d5f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['capital_ratio'] = df_r['text_'].apply(capital_letter_ratio)\n",
    "df_r[['text_', 'capital_ratio']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776af40-4d8f-4067-9121-a609ae3224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_count(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "\n",
    "    return len(re.findall(r\"[^\\w\\s]\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213582a6-6b2e-4275-aa46-072ce9d21b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['punctuation_count'] = df_r['text_'].apply(punctuation_count)\n",
    "df_r[['text_', 'punctuation_count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b0d4a-ecdb-47fb-9f82-da738f51f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excessive_punctuation_score(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    matches = re.findall(r\"[!?]{2,}\", text)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1ac29-591c-40da-9410-6c781cb63e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['excessive_punctuation'] = df_r['text_'].apply(excessive_punctuation_score)\n",
    "df_r[['text_', 'excessive_punctuation']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605f70d-0aaf-4b06-8474-0bbd55357e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['text_', 'capital_ratio', 'punctuation_count', 'excessive_punctuation']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25418f-9107-4778-a126-619248547287",
   "metadata": {},
   "source": [
    "#### Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ce1c2-cc36-4a76-9786-42a396525847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraction expansion\n",
    "import contractions\n",
    "def expand_contractions(text_):\n",
    "    if pd.isna(text_):\n",
    "        return \"\"\n",
    "    return contractions.fix(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2de3ef-e8e7-4d46-af5a-ac2d1410f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"I don't like this product\",\n",
    "    \"It's not what I've expected\",\n",
    "    \"You're going to love it\",\n",
    "    \"They can't believe it's true\",\n",
    "    \"This is fine\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(\"BEFORE:\", s)\n",
    "    print(\"AFTER :\", expand_contractions(s))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed4258-8477-4c75-99d1-ef862a7fc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text - lowercase, url, html tags, punctiation, whitespaces\n",
    "def clean_text(text_):\n",
    "    if pd.isna(text_):\n",
    "        return \"\"\n",
    "    \n",
    "    text_ = text_.lower()\n",
    "    \n",
    "    text_ = re.sub(r'http\\S+|www\\S+', '', text_)\n",
    "    text_ = re.sub(r'<.*?>', '', text_)\n",
    "    \n",
    "    # remove punctuation (letters + spaces only)\n",
    "    text_ = re.sub(r'[^a-z\\s]', '', text_)\n",
    "    \n",
    "    text_ = re.sub(r'\\s+', ' ', text_).strip()\n",
    "    \n",
    "    return text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f299b0-7bdc-4471-8077-99250cb533e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['expanded_text'] = df_r['text_'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453bfb1-19b8-482e-b470-679639c508d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['clean_text'] = df_r['expanded_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39c574-3ffc-41c1-9592-db150738cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['text_', 'expanded_text', 'clean_text']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0724d-6c18-42cc-8c3e-86efa3a5abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    \"WOW!!! 10/10 would buy again!!! üòç\",\n",
    "    \"<p>Best product ever</p>\",\n",
    "    \"Visit http://example.com NOW\",\n",
    "    \"   Multiple     spaces   \",\n",
    "    None\n",
    "]\n",
    "\n",
    "for t in test_cases:\n",
    "    print(\"INPUT :\", t)\n",
    "    print(\"OUTPUT:\", clean_text(t))\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89fd1f-3d72-4db8-acbc-9969b8f40862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "import nltk\n",
    "\n",
    "# nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04968bf-7d36-46e0-8563-e449c5aff47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742214b-b1e8-4db8-b93d-2b687a4a47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lemmatization tools\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4d540-45a7-4093-9d8a-a8c0f528d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjective_ratio(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0\n",
    "    \n",
    "    tokens = word_tokenize(text)        \n",
    "    pos_tags = pos_tag(tokens)          \n",
    "    \n",
    "    adj_count = sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    return adj_count / total_words if total_words > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b88f3-deb0-458f-a77c-3ecc2c3b75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['adjective_ratio'] = df_r['clean_text'].apply(adjective_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c15b47-0742-4489-8aa2-2b821222d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['clean_text', 'adjective_ratio']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d85d0d-d4ff-466d-a2e8-a9b474d7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e8077-1d2d-419e-9ca5-a8babc5166e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Compound score ranges from -1 (very negative) to +1 (very positive)\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18dd2a-8ebc-40d1-9d59-13d9a802e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['sentiment_score'] = df_r['clean_text'].apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52019ce4-4adc-4843-a62d-7c27ad99c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['clean_text', 'sentiment_score']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9062de-f137-402c-b839-b2dd74530bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['text_length'] = df_r['clean_text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55a51f-92aa-4812-a163-24a22c942eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['clean_text', 'text_length']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9662939-413c-40de-8e41-475d181f17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_text(text_):\n",
    "    if pd.isna(text_) or text_ == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    tokens = wordpunct_tokenize(text_)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    lemmatized_words = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
    "        for word, tag in pos_tags\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544deb47-e042-437b-b731-cc9a4ec8520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"running faster than others\",\n",
    "    \"better products were bought\",\n",
    "    \"he was buying expensive items\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(\"BEFORE:\", s)\n",
    "    print(\"AFTER :\", lemmatize_text(s))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f02f5d-6b51-4292-a17d-12019b91cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['lemmatized_text'] = df_r['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef644cd-85e8-4353-bf6d-a43808a31522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[['text_', 'expanded_text', 'clean_text', 'lemmatized_text']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921c3f5-8265-46ee-86a7-98514dfafeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.rename(columns={'lemmatized_text': 'review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e39e5d-6e80-4651-89e4-0739ccbbd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r['label'] = df_r['label'].map({'CG': 0, 'OR': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cbf2f-4489-458e-b891-1b7a4c5619a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.9,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(df_r['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe217ee-aa2f-46f3-b3dd-26af08395cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a646f7c-e333-4886-ab01-9e372472ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37028a51-ddc9-4986-bd69-b798a59503b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf                   \n",
    "df_r[['adjective_ratio',\n",
    "      'sentiment_score',\n",
    "      'text_length',\n",
    "      'capital_ratio',\n",
    "      'punctuation_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1520d-7f08-49a7-b3f2-d404ee932314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_extra = df_r[\n",
    "    ['adjective_ratio',\n",
    "     'sentiment_score',\n",
    "     'text_length',\n",
    "     'capital_ratio',\n",
    "     'punctuation_count']\n",
    "].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c5c9c-4a18-4f71-9e08-04aeecc22772",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b89939-bd24-4d08-9394-8ec55f3fd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = hstack([X_tfidf, X_extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e91225-6a96-44e9-a1d4-5c1c27e21b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf.shape\n",
    "X_extra.shape\n",
    "X_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa2b39-d4d4-46e1-bc39-4f8444a60788",
   "metadata": {},
   "source": [
    "#### Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d627dd-92f4-49c6-89cf-d785a6961337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fbcd8-887f-4be6-aa6a-3e623395f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_df = df_r[\n",
    "#     ['rating', 'review', 'label', 'text_length',\n",
    "#      'capital_ratio', 'punctuation_count', 'excessive_punctuation']\n",
    "# ]\n",
    "\n",
    "# # Save as CSV\n",
    "# pre_df.to_csv(\"preprocessed_dataset.csv\", index=False)\n",
    "# print(\"Preprocessed dataset saved as CSV!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
