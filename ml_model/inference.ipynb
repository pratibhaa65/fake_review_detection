{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import contractions\n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8507da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load all required models\n",
    "classifier = joblib.load(\"../joblib/logistic_fake_review_model.pkl\")\n",
    "tfidf_lemm = joblib.load(\"../joblib/lemm_tfidf_vectorizer.pkl\")\n",
    "tfidf_raw = joblib.load(\"../joblib/raw_tfidf_vectorizer.pkl\")\n",
    "nn_raw = joblib.load(\"../joblib/raw_nn_model.pkl\")\n",
    "nn_lemm = joblib.load(\"../joblib/lemm_nn_model.pkl\")\n",
    "category_centroids = joblib.load(\"../joblib/category_centroids.pkl\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def capital_letter_ratio(text):\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if len(letters) == 0: return 0\n",
    "    capitals = [c for c in letters if c.isupper()]\n",
    "    return len(capitals) / len(letters)\n",
    "\n",
    "def punctuation_ratio(text):\n",
    "    if not text: return 0\n",
    "    return len(re.findall(r\"[^\\w\\s]\", text)) / len(text)\n",
    "\n",
    "def repetition_score(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    if not words: return 0\n",
    "    return 1 - len(set(words)) / len(words)\n",
    "\n",
    "def expand_text(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def adjective_ratio(text):\n",
    "    if not text.strip(): return 0\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    adj_count = sum(1 for w, t in tags if t.startswith('JJ'))\n",
    "    return adj_count / len(tokens) if tokens else 0\n",
    "\n",
    "def sentiment_score(text):\n",
    "    if not text.strip(): return 0\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "def rating_polarity(r):\n",
    "    if r >= 4: return 1\n",
    "    elif r <= 2: return -1\n",
    "    return 0\n",
    "\n",
    "def rating_sentiment_mismatch(sentiment, rating):\n",
    "    rp = rating_polarity(rating)\n",
    "    if rp == 1 and sentiment < -0.2: return 1\n",
    "    if rp == -1 and sentiment > 0.2: return 1\n",
    "    return 0\n",
    "\n",
    "def is_extreme_rating(r):\n",
    "    return 1 if r in [1, 5] else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def raw_review_similarity(review_text):\n",
    "    vec = tfidf_raw.transform([review_text])\n",
    "    distances, indices = nn_raw.kneighbors(vec)\n",
    "    sims = 1 - distances\n",
    "    return sims[0][1:].max()  # max excluding self\n",
    "\n",
    "def clean_review_similarity(review_text):\n",
    "    vec = tfidf_lemm.transform([review_text])\n",
    "    distances, indices = nn_lemm.kneighbors(vec)\n",
    "    sims = 1 - distances\n",
    "    return sims[0][1:].max()\n",
    "\n",
    "def category_consistency_score(cleaned_text, category):\n",
    "    if category not in category_centroids:\n",
    "        return 0.0\n",
    "    vec = tfidf_lemm.transform([cleaned_text])\n",
    "    centroid = category_centroids[category]\n",
    "    return cosine_similarity(vec, centroid)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_predict(review_text, rating, category):\n",
    "\n",
    "    # --- Stateless features ---\n",
    "    text_length = len(review_text)\n",
    "    capital_ratio = capital_letter_ratio(review_text)\n",
    "    punct_ratio = punctuation_ratio(review_text)\n",
    "    rep_score = repetition_score(review_text)\n",
    "    extreme_rating = 1 if rating in [1, 5] else 0\n",
    "\n",
    "    exp_text = expand_text(review_text)\n",
    "    cleaned_text = clean_text(exp_text)\n",
    "    adj_ratio = adjective_ratio(cleaned_text)\n",
    "    sent_score = sentiment_score(cleaned_text)\n",
    "\n",
    "    rating_pol = 1 if rating >= 4 else -1 if rating <= 2 else 0\n",
    "    mismatch = int(\n",
    "        (rating_pol == 1 and sent_score < -0.2) or\n",
    "        (rating_pol == -1 and sent_score > 0.2)\n",
    "    )\n",
    "\n",
    "    # --- Raw similarity ---\n",
    "    raw_vec = tfidf_raw.transform([review_text])\n",
    "    raw_dist, _ = nn_raw.kneighbors(raw_vec)\n",
    "    raw_sim = (1 - raw_dist[:, 1:]).max()\n",
    "\n",
    "    # --- Clean similarity ---\n",
    "    clean_vec = tfidf_lemm.transform([cleaned_text])\n",
    "    clean_dist, _ = nn_lemm.kneighbors(clean_vec)\n",
    "    review_sim = (1 - clean_dist[:, 1:]).max()\n",
    "\n",
    "    # --- Category consistency ---\n",
    "    centroid = category_centroids.get(category)\n",
    "    cat_score = cosine_similarity(clean_vec, centroid)[0][0] if centroid is not None else 0\n",
    "\n",
    "    # --- Numeric features (ORDER MUST MATCH TRAINING) ---\n",
    "    numeric_features = np.array([[\n",
    "        text_length,\n",
    "        capital_ratio,\n",
    "        punct_ratio,\n",
    "        adj_ratio,\n",
    "        sent_score,\n",
    "        mismatch,\n",
    "        raw_sim,\n",
    "        cat_score,\n",
    "        review_sim,\n",
    "        rep_score,\n",
    "        extreme_rating\n",
    "    ]])\n",
    "\n",
    "    # --- FINAL FEATURE VECTOR ---\n",
    "    X_final = hstack([clean_vec, numeric_features])\n",
    "\n",
    "    # --- Sanity check ---\n",
    "    assert X_final.shape[1] == classifier.n_features_in_\n",
    "\n",
    "    # --- Predict ---\n",
    "    prob = classifier.predict_proba(X_final)[0][1]\n",
    "    label = \"FAKE\" if prob >= 0.5 else \"GENUINE\"\n",
    "\n",
    "    return label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdaed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
