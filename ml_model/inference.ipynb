{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7889219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n",
    "import contractions\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8507da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "clf = joblib.load(\"../joblib/logistic_fake_review_model.pkl\")\n",
    "\n",
    "# TF-IDF + NN models\n",
    "raw_tfidf = joblib.load(\"../joblib/raw_tfidf_vectorizer.pkl\")\n",
    "raw_nn = joblib.load(\"../joblib/raw_nn_model.pkl\")\n",
    "\n",
    "lemm_tfidf = joblib.load(\"../joblib/lemm_tfidf_vectorizer.pkl\")\n",
    "lemm_nn = joblib.load(\"../joblib/lemm_nn_model.pkl\")\n",
    "\n",
    "# Category centroids\n",
    "category_centroids = joblib.load(\"../joblib/category_centroids.pkl\")\n",
    "\n",
    "# Numeric feature order\n",
    "numeric_feature_order = joblib.load(\"../joblib/numeric_feature_order.pkl\")\n",
    "\n",
    "# NLP tools\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e756856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_letter_ratio(text):\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    if not letters:\n",
    "        return 0.0\n",
    "    return sum(1 for c in letters if c.isupper()) / len(letters)\n",
    "\n",
    "def punctuation_ratio(text):\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    return len(re.findall(r\"[^\\w\\s]\", text)) / len(text)\n",
    "\n",
    "def repetition_score(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    return 1 - len(set(words)) / len(words)\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text) if isinstance(text, str) else \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def adjective_ratio(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "    tags = pos_tag(tokens)\n",
    "    return sum(1 for _, t in tags if t.startswith(\"JJ\")) / len(tokens)\n",
    "\n",
    "def sentiment_score(text):\n",
    "    return sia.polarity_scores(text)[\"compound\"] if text else 0.0\n",
    "\n",
    "def rating_polarity(r):\n",
    "    if r >= 4:\n",
    "        return 1\n",
    "    if r <= 2:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def rating_sentiment_mismatch(sentiment, rating):\n",
    "    rp = rating_polarity(rating)\n",
    "    if rp == 1 and sentiment < -0.2:\n",
    "        return 1\n",
    "    if rp == -1 and sentiment > 0.2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join(t.lemma_ for t in doc if not t.is_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac38c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_review_similarity(text):\n",
    "    vec = raw_tfidf.transform([text])\n",
    "    distances, _ = raw_nn.kneighbors(vec)\n",
    "    sims = 1 - distances\n",
    "    return sims[0, 1:].max()\n",
    "\n",
    "def lemm_review_similarity(text):\n",
    "    vec = lemm_tfidf.transform([text])\n",
    "    distances, _ = lemm_nn.kneighbors(vec)\n",
    "    sims = 1 - distances\n",
    "    return sims[0, 1:].max()\n",
    "\n",
    "def category_consistency(text, category):\n",
    "    if category not in category_centroids:\n",
    "        return 0.0\n",
    "    vec = lemm_tfidf.transform([text])\n",
    "    centroid = category_centroids[category]\n",
    "    return cosine_similarity(vec, centroid)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055b6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(review, rating, category):\n",
    "    # ---------- RAW ----------\n",
    "    text_length = len(review)\n",
    "    cap_ratio = capital_letter_ratio(review)\n",
    "    punct_ratio = punctuation_ratio(review)\n",
    "    rep_score = repetition_score(review)\n",
    "\n",
    "    # ---------- CLEAN ----------\n",
    "    expanded = expand_contractions(review)\n",
    "    cleaned = clean_text(expanded)\n",
    "\n",
    "    adj_ratio = adjective_ratio(cleaned)\n",
    "    sent_score = sentiment_score(cleaned)\n",
    "    mismatch = rating_sentiment_mismatch(sent_score, rating)\n",
    "    extreme = 1 if rating in [1, 5] else 0\n",
    "\n",
    "    # ---------- LEMMATIZED ----------\n",
    "    lemm = lemmatize(cleaned)\n",
    "\n",
    "    # ---------- STATEFUL ----------\n",
    "    raw_sim = raw_review_similarity(review)\n",
    "    lemm_sim = lemm_review_similarity(lemm)\n",
    "    cat_score = category_consistency(lemm, category)\n",
    "\n",
    "    # ---------- NUMERIC VECTOR ----------\n",
    "    numeric_dict = {\n",
    "        'text_length': text_length,\n",
    "        'capital_ratio': cap_ratio,\n",
    "        'punctuation_ratio': punct_ratio,\n",
    "        'adjective_ratio': adj_ratio,\n",
    "        'sentiment_score': sent_score,\n",
    "        'rating_sentiment_mismatch': mismatch,\n",
    "        'raw_review_similarity': raw_sim,\n",
    "        'category_consistency_score': cat_score,\n",
    "        'review_similarity_score': lemm_sim,\n",
    "        'repetition_score': rep_score,\n",
    "        'is_extreme_rating': extreme\n",
    "    }\n",
    "\n",
    "    numeric_values = np.array([[numeric_dict[f] for f in numeric_feature_order]])\n",
    "\n",
    "    # ---------- FINAL MATRIX ----------\n",
    "    X_text = lemm_tfidf.transform([lemm])\n",
    "    X_final = hstack([X_text, numeric_values])\n",
    "\n",
    "    # ---------- PREDICTION ----------\n",
    "    pred = clf.predict(X_final)[0]\n",
    "    prob = clf.predict_proba(X_final)[0, 1]\n",
    "\n",
    "    return {\n",
    "        \"prediction\": \"Genuine\" if pred == 1 else \"Fake\",\n",
    "        \"probability\": float(prob)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87cdaed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'Genuine', 'probability': 0.6404654947180597}\n"
     ]
    }
   ],
   "source": [
    "result = predict_review(\n",
    "    review=\"The product is very bad and I am extremely disappointed with my purchase.\",\n",
    "    rating=5,\n",
    "    category=\"Accessories\"\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2a651c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>1.589861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>1.522377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>1.178359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.150399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.137174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>0.974208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>0.877822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>0.806413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>0.743794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>punctuation_ratio</td>\n",
       "      <td>0.732988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>0.730715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>0.687413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.641990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.622864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>0.605230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>0.536625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>0.536086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>0.528077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>0.521040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>0.517068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature    weight\n",
       "40           tfidf_40  1.589861\n",
       "5             tfidf_5  1.522377\n",
       "9             tfidf_9  1.178359\n",
       "44           tfidf_44  1.150399\n",
       "34           tfidf_34  1.137174\n",
       "28           tfidf_28  0.974208\n",
       "21           tfidf_21  0.877822\n",
       "24           tfidf_24  0.806413\n",
       "49           tfidf_49  0.743794\n",
       "60  punctuation_ratio  0.732988\n",
       "39           tfidf_39  0.730715\n",
       "18           tfidf_18  0.687413\n",
       "2             tfidf_2  0.641990\n",
       "0             tfidf_0  0.622864\n",
       "29           tfidf_29  0.605230\n",
       "45           tfidf_45  0.536625\n",
       "37           tfidf_37  0.536086\n",
       "55           tfidf_55  0.528077\n",
       "11           tfidf_11  0.521040\n",
       "20           tfidf_20  0.517068"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load trained model\n",
    "lr = joblib.load(\"../joblib/logistic_fake_review_model.pkl\")\n",
    "\n",
    "# Load numeric feature names\n",
    "numeric_features = joblib.load(\"../joblib/numeric_feature_order.pkl\")\n",
    "\n",
    "# Total number of features model was trained on\n",
    "total_features = lr.coef_.shape[1]\n",
    "\n",
    "# TF-IDF feature count\n",
    "tfidf_dim = total_features - len(numeric_features)\n",
    "\n",
    "# Create feature name list\n",
    "all_features = (\n",
    "    [f\"tfidf_{i}\" for i in range(tfidf_dim)] +\n",
    "    numeric_features\n",
    ")\n",
    "\n",
    "# Create importance dataframe\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": all_features,\n",
    "    \"weight\": lr.coef_[0]\n",
    "}).sort_values(by=\"weight\", ascending=False)\n",
    "\n",
    "coef_df.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a12b608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>punctuation_ratio</td>\n",
       "      <td>0.732988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>review_similarity_score</td>\n",
       "      <td>0.375728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>adjective_ratio</td>\n",
       "      <td>0.244999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>sentiment_score</td>\n",
       "      <td>0.230189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>is_extreme_rating</td>\n",
       "      <td>0.021301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>text_length</td>\n",
       "      <td>0.005975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rating_sentiment_mismatch</td>\n",
       "      <td>-0.478925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>category_consistency_score</td>\n",
       "      <td>-0.712102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>capital_ratio</td>\n",
       "      <td>-0.943445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>repetition_score</td>\n",
       "      <td>-11.260963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>raw_review_similarity</td>\n",
       "      <td>-16.351109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature     weight\n",
       "60           punctuation_ratio   0.732988\n",
       "66     review_similarity_score   0.375728\n",
       "61             adjective_ratio   0.244999\n",
       "62             sentiment_score   0.230189\n",
       "68           is_extreme_rating   0.021301\n",
       "58                 text_length   0.005975\n",
       "63   rating_sentiment_mismatch  -0.478925\n",
       "65  category_consistency_score  -0.712102\n",
       "59               capital_ratio  -0.943445\n",
       "67            repetition_score -11.260963\n",
       "64       raw_review_similarity -16.351109"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df[coef_df['feature'].isin(numeric_features)].sort_values(\n",
    "    by=\"weight\", ascending=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
